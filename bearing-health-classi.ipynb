{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12059457,"sourceType":"datasetVersion","datasetId":7590266}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:28:48.835026Z","iopub.execute_input":"2025-06-04T20:28:48.835746Z","iopub.status.idle":"2025-06-04T20:28:48.870096Z","shell.execute_reply.started":"2025-06-04T20:28:48.835715Z","shell.execute_reply":"2025-06-04T20:28:48.869514Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/bearing-data/B021_2.mat\n/kaggle/input/bearing-data/B028_3.mat\n/kaggle/input/bearing-data/IR007_3.mat\n/kaggle/input/bearing-data/IR014_3.mat\n/kaggle/input/bearing-data/OR00712_2.mat\n/kaggle/input/bearing-data/IR028_2.mat\n/kaggle/input/bearing-data/B014_3.mat\n/kaggle/input/bearing-data/IR014_0.mat\n/kaggle/input/bearing-data/IR007_2.mat\n/kaggle/input/bearing-data/OR0073_1.mat\n/kaggle/input/bearing-data/Normal_3.mat\n/kaggle/input/bearing-data/IR028_0.mat\n/kaggle/input/bearing-data/B021_1.mat\n/kaggle/input/bearing-data/B028_1.mat\n/kaggle/input/bearing-data/IR014_1.mat\n/kaggle/input/bearing-data/Normal_1.mat\n/kaggle/input/bearing-data/OR0076_1.mat\n/kaggle/input/bearing-data/B007_1.mat\n/kaggle/input/bearing-data/B014_0.mat\n/kaggle/input/bearing-data/OR0146_2.mat\n/kaggle/input/bearing-data/B014_1.mat\n/kaggle/input/bearing-data/OR0216_3.mat\n/kaggle/input/bearing-data/B028_0.mat\n/kaggle/input/bearing-data/OR02112_2.mat\n/kaggle/input/bearing-data/B007_3.mat\n/kaggle/input/bearing-data/OR0146_0.mat\n/kaggle/input/bearing-data/B007_2.mat\n/kaggle/input/bearing-data/OR0213_3.mat\n/kaggle/input/bearing-data/OR0213_1.mat\n/kaggle/input/bearing-data/IR021_0.mat\n/kaggle/input/bearing-data/IR028_1.mat\n/kaggle/input/bearing-data/B028_2.mat\n/kaggle/input/bearing-data/OR0213_0.mat\n/kaggle/input/bearing-data/OR0216_1.mat\n/kaggle/input/bearing-data/B014_2.mat\n/kaggle/input/bearing-data/OR0213_2.mat\n/kaggle/input/bearing-data/OR02112_0.mat\n/kaggle/input/bearing-data/OR0216_2.mat\n/kaggle/input/bearing-data/B021_3.mat\n/kaggle/input/bearing-data/Normal_2.mat\n/kaggle/input/bearing-data/IR014_2.mat\n/kaggle/input/bearing-data/IR021_2.mat\n/kaggle/input/bearing-data/B021_0.mat\n/kaggle/input/bearing-data/OR00712_1.mat\n/kaggle/input/bearing-data/OR0146_1.mat\n/kaggle/input/bearing-data/OR0216_0.mat\n/kaggle/input/bearing-data/OR00712_3.mat\n/kaggle/input/bearing-data/B007_0.mat\n/kaggle/input/bearing-data/OR0076_0.mat\n/kaggle/input/bearing-data/OR00712_0.mat\n/kaggle/input/bearing-data/IR007_0.mat\n/kaggle/input/bearing-data/OR0073_3.mat\n/kaggle/input/bearing-data/IR021_3.mat\n/kaggle/input/bearing-data/OR02112_3.mat\n/kaggle/input/bearing-data/IR021_1.mat\n/kaggle/input/bearing-data/IR007_1.mat\n/kaggle/input/bearing-data/Normal_0.mat\n/kaggle/input/bearing-data/IR028_3.mat\n/kaggle/input/bearing-data/OR0073_0.mat\n/kaggle/input/bearing-data/OR0076_2.mat\n/kaggle/input/bearing-data/OR02112_1.mat\n/kaggle/input/bearing-data/OR0073_2.mat\n/kaggle/input/bearing-data/OR0076_3.mat\n/kaggle/input/bearing-data/OR0146_3.mat\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.signal import spectrogram\nfrom scipy.stats import kurtosis, skew\nfrom tqdm import tqdm\nimport glob\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:28:48.871228Z","iopub.execute_input":"2025-06-04T20:28:48.871423Z","iopub.status.idle":"2025-06-04T20:28:48.875921Z","shell.execute_reply.started":"2025-06-04T20:28:48.871409Z","shell.execute_reply":"2025-06-04T20:28:48.875276Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"sampling_rate = 12000\nwindow_sec = 5\nout_shape = (128, 128)\ndata_path = \"/kaggle/input/bearing-data\"  \n\n\ndef classify_file(filename):\n    if \"IR\" in filename:\n        return 1  \n    elif \"B0\" in filename:\n        return 3  \n    elif \"OR\" in filename:\n        return 2  \n    elif \"Normal\" in filename or \"\" in filename:\n        return 0  \n    else:\n        return -1  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:28:48.876510Z","iopub.execute_input":"2025-06-04T20:28:48.876781Z","iopub.status.idle":"2025-06-04T20:28:48.893219Z","shell.execute_reply.started":"2025-06-04T20:28:48.876759Z","shell.execute_reply":"2025-06-04T20:28:48.892599Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def segment_signal(signal, fs=12000, window_sec=5):\n    win_len = fs * window_sec\n    segments = []\n    for start in range(0, len(signal), win_len):\n        chunk = signal[start:start+win_len]\n        if len(chunk) == win_len:\n            segments.append(chunk)\n    return segments\n\ndef segment_to_spectrogram(segment, fs=12000, out_shape=(128, 128)):\n    f, t, Sxx = spectrogram(segment, fs, nperseg=256, noverlap=128)\n    Sxx_db = 10 * np.log10(Sxx + 1e-8)\n    out = np.zeros(out_shape)\n    h, w = min(Sxx_db.shape[0], out_shape[0]), min(Sxx_db.shape[1], out_shape[1])\n    out[:h, :w] = Sxx_db[:h, :w]\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:28:48.893921Z","iopub.execute_input":"2025-06-04T20:28:48.894141Z","iopub.status.idle":"2025-06-04T20:28:48.908113Z","shell.execute_reply.started":"2025-06-04T20:28:48.894127Z","shell.execute_reply":"2025-06-04T20:28:48.907521Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"X, y = [], []\nmat_files = glob.glob(os.path.join(data_path, \"*.mat\"))\n\nfor filepath in tqdm(mat_files):\n    try:\n        fname = os.path.basename(filepath)\n        label = classify_file(fname)\n        if label == -1:\n            continue  # skip unknown types\n\n        data = loadmat(filepath)\n        key = [k for k in data.keys() if \"DE_time\" in k][0]  # auto-detect key\n        signal = data[key].ravel()\n\n        segments = segment_signal(signal, fs=sampling_rate, window_sec=window_sec)\n        for seg in segments:\n            spec = segment_to_spectrogram(seg, fs=sampling_rate, out_shape=out_shape)\n            X.append(spec)\n            y.append(label)\n\n    except Exception as e:\n        print(f\"Error processing {filepath}: {e}\")\n\n\nX = np.array(X)\ny = np.array(y)\nX = X[..., np.newaxis]  \n\n\nprint(\"Final dataset:\")\nprint(\"Total samples:\", X.shape[0])\nprint(\"Shape of each image:\", X.shape[1:])\nprint(\"Label distribution:\", pd.Series(y).value_counts().sort_index().to_dict())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:28:48.909608Z","iopub.execute_input":"2025-06-04T20:28:48.909823Z","iopub.status.idle":"2025-06-04T20:28:49.379056Z","shell.execute_reply.started":"2025-06-04T20:28:48.909809Z","shell.execute_reply":"2025-06-04T20:28:49.378357Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 64/64 [00:00<00:00, 145.20it/s]","output_type":"stream"},{"name":"stdout","text":"Final dataset:\nTotal samples: 148\nShape of each image: (128, 128, 1)\nLabel distribution: {0: 28, 1: 32, 2: 56, 3: 32}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"\nX, y = [], []\nmat_files = glob.glob(os.path.join(data_path, \"*.mat\"))\n\nfor filepath in tqdm(mat_files):\n    try:\n        fname = os.path.basename(filepath)\n        label = classify_file(fname)\n        if label == -1:\n            continue  # skip unknown types\n\n        data = loadmat(filepath)\n        key = [k for k in data.keys() if \"DE_time\" in k][0]  # auto-detect key\n        signal = data[key].ravel()\n\n        segments = segment_signal(signal, fs=sampling_rate, window_sec=window_sec)\n        for seg in segments:\n            # Original\n            spec = segment_to_spectrogram(seg, fs=sampling_rate, out_shape=out_shape)\n            X.append(spec)\n            y.append(label)\n\n            # Augmentation 1: Add Gaussian noise\n            noisy = seg + np.random.normal(0, 0.01, size=seg.shape)\n            noisy_spec = segment_to_spectrogram(noisy, fs=sampling_rate, out_shape=out_shape)\n            X.append(noisy_spec)\n            y.append(label)\n\n            # Augmentation 2: Time shift (roll)\n            shifted = np.roll(seg, 200)\n            shifted_spec = segment_to_spectrogram(shifted, fs=sampling_rate, out_shape=out_shape)\n            X.append(shifted_spec)\n            y.append(label)\n\n    except Exception as e:\n        print(f\"Error processing {filepath}: {e}\")\n\n\nX = np.array(X)\ny = np.array(y)\nX = X[..., np.newaxis]  \n\n# Summary\nprint(\"Final dataset:\")\nprint(\"Total samples:\", X.shape[0])\nprint(\"Shape of each image:\", X.shape[1:])\nprint(\"Label distribution:\", pd.Series(y).value_counts().sort_index().to_dict())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:28:49.379792Z","iopub.execute_input":"2025-06-04T20:28:49.380080Z","iopub.status.idle":"2025-06-04T20:28:50.782979Z","shell.execute_reply.started":"2025-06-04T20:28:49.380062Z","shell.execute_reply":"2025-06-04T20:28:50.782254Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 64/64 [00:01<00:00, 46.68it/s]","output_type":"stream"},{"name":"stdout","text":"Final dataset:\nTotal samples: 444\nShape of each image: (128, 128, 1)\nLabel distribution: {0: 84, 1: 96, 2: 168, 3: 96}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# --- Cross-Validation Block with Improvements ---\nprint(\"\\n--- 5-Fold Cross Validation ---\")\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\naccuracies = []\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n    print(f\"Fold {fold}\")\n    unique, counts = np.unique(y[test_idx], return_counts=True)\n    print(\"Test set label distribution:\", dict(zip(unique, counts)))\n\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(128, 128, 1)),\n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D((2, 2)),\n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D((2, 2)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(4, activation='softmax')\n    ])\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    model.fit(X[train_idx], y[train_idx], epochs=10, verbose=0)\n    y_pred = model.predict(X[test_idx]).argmax(axis=1)\n    acc = accuracy_score(y[test_idx], y_pred)\n    print(f\"Accuracy: {acc:.4f}\\n\")\n    accuracies.append(acc)\n\nprint(\"Cross-validation accuracies:\", [round(a, 4) for a in accuracies])\nprint(\"Average accuracy:\", round(np.mean(accuracies), 4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:28:50.784102Z","iopub.execute_input":"2025-06-04T20:28:50.784305Z","iopub.status.idle":"2025-06-04T20:29:13.904220Z","shell.execute_reply.started":"2025-06-04T20:28:50.784289Z","shell.execute_reply":"2025-06-04T20:29:13.903623Z"}},"outputs":[{"name":"stdout","text":"\n--- 5-Fold Cross Validation ---\nFold 1\nTest set label distribution: {0: 17, 1: 19, 2: 33, 3: 20}\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\nAccuracy: 1.0000\n\nFold 2\nTest set label distribution: {0: 17, 1: 20, 2: 33, 3: 19}\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\nAccuracy: 0.3708\n\nFold 3\nTest set label distribution: {0: 17, 1: 19, 2: 34, 3: 19}\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\nAccuracy: 0.9888\n\nFold 4\nTest set label distribution: {0: 17, 1: 19, 2: 34, 3: 19}\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\nAccuracy: 1.0000\n\nFold 5\nTest set label distribution: {0: 16, 1: 19, 2: 34, 3: 19}\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\nAccuracy: 0.9886\n\nCross-validation accuracies: [1.0, 0.3708, 0.9888, 1.0, 0.9886]\nAverage accuracy: 0.8696\n","output_type":"stream"}],"execution_count":33}]}